{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e5b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24077993",
   "metadata": {},
   "source": [
    "# Function creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab66efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state(col1, col2, col3, input_filename, output_folder, output_filename):\n",
    "    \"\"\"\n",
    "    Creates initial state tensor where first column is col1 + col2 and second column is col3.\n",
    "    Saves as a PyTorch tensor with shape [rows, 1, 2].\n",
    "    \n",
    "    Parameters:\n",
    "    col1: First column name (will be added to col2)\n",
    "    col2: Second column name (will be added to col1)\n",
    "    col3: Third column name (becomes second column of tensor)\n",
    "    input_filename: Path to the input CSV file\n",
    "    output_folder: Folder path where to save the tensor\n",
    "    output_filename: Filename for the output tensor (without extension, .pt will be added)\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_filename)\n",
    "    \n",
    "    # Create the two columns: [col1 + col2, col3]\n",
    "    state_data = np.column_stack([\n",
    "        df[col1].values + df[col2].values,  # First column: col1 + col2\n",
    "        df[col3].values                      # Second column: col3\n",
    "    ])\n",
    "    \n",
    "    # Convert to tensor and reshape to [rows, 1, 2]\n",
    "    tensor = torch.tensor(state_data, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Add .pt extension if not present\n",
    "    if not output_filename.endswith('.pt'):\n",
    "        output_filename = output_filename + '.pt'\n",
    "    \n",
    "    # Save tensor\n",
    "    filepath = os.path.join(output_folder, output_filename)\n",
    "    torch.save(tensor, filepath)\n",
    "    \n",
    "    print(f\"Tensor saved to {filepath}\")\n",
    "    print(f\"Tensor shape: {tensor.shape}\")\n",
    "    print(f\"Column 1: {col1} + {col2}\")\n",
    "    print(f\"Column 2: {col3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b673303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df):\n",
    "    \"\"\"\n",
    "    Converts a dataframe to a PyTorch tensor with shape [rows, 1, time].\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with Store, Product columns and date columns\n",
    "    \n",
    "    Returns:\n",
    "    tensor: PyTorch tensor with shape [rows, 1, time]\n",
    "    \"\"\"\n",
    "    # Get all date columns (exclude Store and Product)\n",
    "    date_columns = df.columns.difference(['Store', 'Product'])\n",
    "    \n",
    "    # Sort date columns to ensure chronological order\n",
    "    date_columns = sorted(date_columns)\n",
    "    \n",
    "    # Extract only the date columns as numpy array\n",
    "    data = df[date_columns].values\n",
    "    \n",
    "    # Convert to tensor and reshape to [rows, 1, time]\n",
    "    tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "\n",
    "def save_df_as_tensor(df, folder, filename):\n",
    "    \"\"\"\n",
    "    Saves a dataframe as a PyTorch tensor with shape [rows, 1, time].\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with Store, Product columns and date columns\n",
    "    folder: Folder path where to save the tensor\n",
    "    filename: Filename (without extension, .pt will be added)\n",
    "    \"\"\"\n",
    "    # Create tensor from dataframe\n",
    "    tensor = df_to_tensor(df)\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # Add .pt extension if not present\n",
    "    if not filename.endswith('.pt'):\n",
    "        filename = filename + '.pt'\n",
    "    \n",
    "    # Save tensor\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    torch.save(tensor, filepath)\n",
    "    \n",
    "    print(f\"Tensor saved to {filepath}\")\n",
    "    print(f\"Tensor shape: {tensor.shape}\")\n",
    "\n",
    "def save_tensor(tensor, folder, filename):\n",
    "    \"\"\"\n",
    "    Saves a PyTorch tensor to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    tensor: PyTorch tensor to save\n",
    "    folder: Folder path where to save the tensor\n",
    "    filename: Filename (without extension, .pt will be added)\n",
    "    \"\"\"\n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # Add .pt extension if not present\n",
    "    if not filename.endswith('.pt'):\n",
    "        filename = filename + '.pt'\n",
    "    \n",
    "    # Save tensor\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    torch.save(tensor, filepath)\n",
    "    \n",
    "    print(f\"Tensor saved to {filepath}\")\n",
    "    print(f\"Tensor shape: {tensor.shape}\")\n",
    "\n",
    "def save_df_to_csv(df, folder, filename):\n",
    "    \"\"\"\n",
    "    Saves a dataframe to CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame to save\n",
    "    folder: Folder path where to save the CSV\n",
    "    filename: Filename (without extension, .csv will be added)\n",
    "    \"\"\"\n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # Add .csv extension if not present\n",
    "    if not filename.endswith('.csv'):\n",
    "        filename = filename + '.csv'\n",
    "    \n",
    "    # Create full filepath\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    \n",
    "    # Save to CSV without index\n",
    "    df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"DataFrame saved to {filepath}\")\n",
    "    print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dba3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(df, additional_weeks=0):\n",
    "    \"\"\"\n",
    "    Creates a dataframe with date features from a sales dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with date columns (excluding Store and Product)\n",
    "    additional_weeks: int, number of additional weeks to generate features for (default: 0)\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with columns: date, day_of_week, month_1, month_2, ..., month_12, \n",
    "                           year, day_of_month, days_from_christmas\n",
    "    \"\"\"\n",
    "    # Get all date columns (exclude Store and Product)\n",
    "    date_columns = df.columns.difference(['Store', 'Product'])\n",
    "    date_columns = sorted(date_columns)\n",
    "    \n",
    "    # Convert to datetime\n",
    "    dates = pd.to_datetime(date_columns)\n",
    "    \n",
    "    # Add additional weeks if specified (one date per week, 7 days apart)\n",
    "    if additional_weeks > 0:\n",
    "        last_date = dates[-1]\n",
    "        additional_dates = [last_date + pd.Timedelta(days=7 * (i + 1)) \n",
    "                           for i in range(additional_weeks)]\n",
    "        dates = dates.append(pd.DatetimeIndex(additional_dates))\n",
    "    \n",
    "    # Create the features dataframe\n",
    "    date_features = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'day_of_week': dates.dayofweek,  # Monday=0, Sunday=6\n",
    "        'month': dates.month,\n",
    "        'year': dates.year,\n",
    "        'day_of_month': dates.day\n",
    "    })\n",
    "    \n",
    "    # Create one-hot encoding for months\n",
    "    for month in range(1, 13):\n",
    "        date_features[f'month_{month}'] = (date_features['month'] == month).astype(int)\n",
    "    \n",
    "    # Drop the original month column\n",
    "    date_features = date_features.drop('month', axis=1)\n",
    "    \n",
    "    # Reorder columns to have month columns after day_of_week\n",
    "    cols = ['date', 'day_of_week'] + [f'month_{i}' for i in range(1, 13)] + ['year', 'day_of_month']\n",
    "    date_features = date_features[cols]\n",
    "    \n",
    "    # Calculate days_from_christmas\n",
    "    def calculate_days_from_christmas(date):\n",
    "        # Christmas of the same year\n",
    "        christmas_current = pd.Timestamp(year=date.year, month=12, day=25)\n",
    "        # Christmas of previous year\n",
    "        christmas_prev = pd.Timestamp(year=date.year - 1, month=12, day=25)\n",
    "        # Christmas of next year\n",
    "        christmas_next = pd.Timestamp(year=date.year + 1, month=12, day=25)\n",
    "        \n",
    "        # Calculate days from each Christmas\n",
    "        days_from_current = (date - christmas_current).days\n",
    "        days_from_prev = (date - christmas_prev).days\n",
    "        days_from_next = (date - christmas_next).days\n",
    "        \n",
    "        # Return the one with minimum absolute value\n",
    "        candidates = [days_from_current, days_from_prev, days_from_next]\n",
    "        return min(candidates, key=abs)\n",
    "    \n",
    "    date_features['days_from_christmas'] = date_features['date'].apply(calculate_days_from_christmas)\n",
    "    \n",
    "    return date_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d418f",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17e654",
   "metadata": {},
   "source": [
    "### First, we read the data and create the respective dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e847d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  Product  2021-04-12  2021-04-19  2021-04-26  2021-05-03  2021-05-10  \\\n",
      "0      0      126         0.0         0.0         3.0         3.0         0.0   \n",
      "1      0      182         0.0         0.0         0.0         0.0         0.0   \n",
      "2      1      124        13.0         4.0        10.0         5.0         1.0   \n",
      "3      2      124         5.0         5.0        12.0        16.0        10.0   \n",
      "4      2      126         0.0         0.0         6.0         5.0         7.0   \n",
      "\n",
      "   2021-05-17  2021-05-24  2021-05-31  ...  2024-02-05  2024-02-12  \\\n",
      "0         1.0         1.0         0.0  ...         0.0         2.0   \n",
      "1         0.0         0.0         0.0  ...         1.0         1.0   \n",
      "2         2.0         3.0         4.0  ...         8.0        17.0   \n",
      "3         8.0        10.0         9.0  ...         6.0         8.0   \n",
      "4         4.0         1.0         2.0  ...         2.0         0.0   \n",
      "\n",
      "   2024-02-19  2024-02-26  2024-03-04  2024-03-11  2024-03-18  2024-03-25  \\\n",
      "0         2.0         0.0         0.0         0.0         0.0         0.0   \n",
      "1         0.0         0.0         1.0         1.0         0.0         3.0   \n",
      "2         6.0        11.0         8.0        12.0         6.0         7.0   \n",
      "3         8.0        18.0        11.0        14.0         3.0        12.0   \n",
      "4         2.0         5.0         2.0         2.0         4.0         2.0   \n",
      "\n",
      "   2024-04-01  2024-04-08  \n",
      "0         2.0         2.0  \n",
      "1         1.0         1.0  \n",
      "2         9.0         7.0  \n",
      "3        13.0         2.0  \n",
      "4         3.0         2.0  \n",
      "\n",
      "[5 rows x 159 columns]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "init_state = pd.read_csv('vn2_data/Week 0 - 2024-04-08 - Initial State.csv')\n",
    "sales = pd.read_csv('vn2_data/Week 0 - 2024-04-08 - Sales.csv')\n",
    "stock = pd.read_csv('vn2_data/Week 0 - In Stock.csv')\n",
    "product_info = pd.read_csv('vn2_data/Week 0 - Master.csv')\n",
    "\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d315cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory to save the dataframes and tensors\n",
    "save_directory = 'vn2_processed_data/new_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4388a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor saved to vn2_processed_data/new_data/stock.pt\n",
      "Tensor shape: torch.Size([599, 1, 165])\n",
      "Tensor saved to vn2_processed_data/new_data/sales.pt\n",
      "Tensor shape: torch.Size([599, 1, 157])\n",
      "DataFrame saved to vn2_processed_data/new_data/product_features.csv\n",
      "Shape: (599, 8)\n"
     ]
    }
   ],
   "source": [
    "# Optional: save the dataframes as tensors\n",
    "save_the_dfs = True\n",
    "# this will create a tensor for each dataframe\n",
    "# each tensor will have shape [products, 1, time]\n",
    "if save_the_dfs:\n",
    "    save_df_as_tensor(stock, save_directory, 'stock')\n",
    "    save_df_as_tensor(sales, save_directory, 'sales')  # .pt optional\n",
    "\n",
    "# Optional: save the product info dataframe as a csv file\n",
    "# this will create a csv file with the product information, which agents will use to create a tensor of the respective features size\n",
    "save_product_info = True\n",
    "if save_product_info:\n",
    "    save_df_to_csv(product_info, save_directory, 'product_features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c782f14",
   "metadata": {},
   "source": [
    "#### Here, we create a dataframe that in each row has date-related information. This will be valuable input for the neural policies we create, since it can allow it to learn non-stationary patterns throughout the year, such as the proximity to christmas and the month of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15755e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  day_of_week  month_1  month_2  month_3  month_4  month_5  \\\n",
      "0 2021-04-12            0        0        0        0        1        0   \n",
      "1 2021-04-19            0        0        0        0        1        0   \n",
      "2 2021-04-26            0        0        0        0        1        0   \n",
      "3 2021-05-03            0        0        0        0        0        1   \n",
      "4 2021-05-10            0        0        0        0        0        1   \n",
      "\n",
      "   month_6  month_7  month_8  month_9  month_10  month_11  month_12  year  \\\n",
      "0        0        0        0        0         0         0         0  2021   \n",
      "1        0        0        0        0         0         0         0  2021   \n",
      "2        0        0        0        0         0         0         0  2021   \n",
      "3        0        0        0        0         0         0         0  2021   \n",
      "4        0        0        0        0         0         0         0  2021   \n",
      "\n",
      "   day_of_month  days_from_christmas  \n",
      "0            12                  108  \n",
      "1            19                  115  \n",
      "2            26                  122  \n",
      "3             3                  129  \n",
      "4            10                  136  \n",
      "DataFrame saved to vn2_processed_data/new_data/date_features.csv\n",
      "Shape: (158, 17)\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "# First df is needed to infer the weeks for which to create data.\n",
    "# Additional_weeks allow us to create a date for each week. Remember that when we create predictions, we will use the last row in this df!\n",
    "# For the first round, we need to create a date for the week starting april 15th, so additional_weeks=1\n",
    "date_df = create_date_features(sales, additional_weeks=1)\n",
    "print(date_df.head())\n",
    "\n",
    "# optional: save the date_df to a csv file\n",
    "save_date_df = True\n",
    "if save_date_df:\n",
    "    save_df_to_csv(date_df, save_directory, 'date_features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a9bb9",
   "metadata": {},
   "source": [
    "### The neural policies also accept time-related data for each product. This could represent, for example, that for product i there was a promotion at time t. The resulting tensor has to be of shape [features, products, 1, periods]. When we train our agents, we will create a separate [batch, 1, past periods] tensor for each feature, which will be fed as input to the neural network. As an example, we stack the stock 2 times, to create a tensor of shape [2, products, 1, periods]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18c7f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 599, 1, 165])\n",
      "Tensor saved to vn2_processed_data/new_data/time_product_features.pt\n",
      "Tensor shape: torch.Size([2, 599, 1, 165])\n"
     ]
    }
   ],
   "source": [
    "stock_tensor = df_to_tensor(stock)\n",
    "stock_tensor_2copies = torch.stack([stock_tensor, stock_tensor])\n",
    "print(stock_tensor_2copies.shape)\n",
    "\n",
    "save_time_product_tensor = True\n",
    "# this will create a tensor for the time-product features, which will have shape [features, products, 1, periods]\n",
    "if save_time_product_tensor:\n",
    "    save_tensor(stock_tensor_2copies, save_directory, 'time_product_features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1876d8",
   "metadata": {},
   "source": [
    "### Create a tensor for the initial state, with shape [products, 1, 2] since lead times is of 2 periods (the 1 comes from the number of stores, which here is always 1). We do this by reading a csv, creating a tensor with columns [col1 + col2, col2] and then saving it. This tensor will be used as the initial state of inventory when we create our outputs for submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e49f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor saved to vn2_processed_data/new_data/inventory_state.pt\n",
      "Tensor shape: torch.Size([599, 1, 2])\n",
      "Column 1: End Inventory + In Transit W+1\n",
      "Column 2: In Transit W+2\n"
     ]
    }
   ],
   "source": [
    "# The first columns crresponds to 'End Inventory' + 'In Transit W+1' and the second to 'In Transit W+2'\n",
    "create_initial_state(\n",
    "    col1='End Inventory',\n",
    "    col2='In Transit W+1',\n",
    "    col3='In Transit W+2',\n",
    "    input_filename='vn2_data/Week 0 - 2024-04-08 - Initial State.csv',\n",
    "    output_folder=save_directory,\n",
    "    output_filename='inventory_state'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b5763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
