{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_trained_model(filename, model, trainer, optimizer, config_setting, config_hyperparams):\n",
    "    \"\"\"\n",
    "    Save the trained model that achieved the smallest dev_loss.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : str\n",
    "        The filename to save the model as (without extension)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The full path where the model was saved\n",
    "    \"\"\"\n",
    "    # Get today's date in YYYY_MM_DD format\n",
    "    today = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "    \n",
    "    # Create the directory structure: saved_models/{today's date}/\n",
    "    save_dir = f\"saved_models/{today}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the full path\n",
    "    model_path = f\"{save_dir}/{filename}.pt\"\n",
    "    \n",
    "    # Save the model with all relevant information\n",
    "    torch.save({\n",
    "        'epoch': trainer.best_epoch,\n",
    "        'model_state_dict': trainer.best_performance_data['model_params_to_save'],\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_train_loss': trainer.best_performance_data['train_loss'],\n",
    "        'best_dev_loss': trainer.best_performance_data['dev_loss'],\n",
    "        'all_train_losses': trainer.all_train_losses,\n",
    "        'all_dev_losses': trainer.all_dev_losses,\n",
    "        'all_test_losses': trainer.all_test_losses,\n",
    "        'warehouse_upper_bound': model.warehouse_upper_bound,\n",
    "        'config_setting': config_setting,\n",
    "        'config_hyperparams': config_hyperparams,\n",
    "        'save_timestamp': datetime.now().isoformat()\n",
    "    }, model_path)\n",
    "    \n",
    "    print(f\"Model saved successfully!\")\n",
    "    print(f\"Path: {model_path}\")\n",
    "    print(f\"Best dev loss: {trainer.best_performance_data['dev_loss']:.6f}\")\n",
    "    print(f\"Best epoch: {trainer.best_epoch + 1}\")\n",
    "    \n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function to make predictions using config files\n",
    "import numpy as np\n",
    "\n",
    "def make_predictions_from_config(model, device, config_setting_file=None, config_hyperparams_file=None, \n",
    "                                inventory_state_path=None, data_dir=None, time_period_idx=None, round_predictions=True):\n",
    "    \"\"\"\n",
    "    Make predictions using a trained model by reading configuration files and automatically\n",
    "    building the observation data structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The trained model\n",
    "    device : str\n",
    "        Device to run inference on\n",
    "    config_setting_file : str, optional\n",
    "        Path to settings config file. If None, uses the current config files from the session.\n",
    "    config_hyperparams_file : str, optional  \n",
    "        Path to hyperparams config file. If None, uses the current config files from the session.\n",
    "    inventory_state_path : str, optional\n",
    "        Path to inventory state file. If None, uses default path.\n",
    "    data_dir : str, optional\n",
    "        Directory containing data files. If None, uses default path.\n",
    "    time_period_idx : int, optional\n",
    "        Time period index to use for prediction. If None, uses the last period.\n",
    "    round_predictions : bool, optional\n",
    "        Whether to round predictions to the nearest integer. Default is True.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : dict\n",
    "        Dictionary containing model predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use current config if not provided\n",
    "    if config_setting_file is None:\n",
    "        config_setting_file = 'config_files/settings/vn2_round_1.yml'\n",
    "    if config_hyperparams_file is None:\n",
    "        config_hyperparams_file = 'config_files/policies_and_hyperparams/data_driven_net.yml'\n",
    "    if inventory_state_path is None:\n",
    "        inventory_state_path = 'vn2_processed_data/all_data/inventory_state.pt'\n",
    "    if data_dir is None:\n",
    "        data_dir = 'vn2_processed_data/all_data/'\n",
    "    \n",
    "    # Load configuration files\n",
    "    print(\"Loading configuration files...\")\n",
    "    with open(config_setting_file, 'r') as file:\n",
    "        config_setting = yaml.safe_load(file)\n",
    "    \n",
    "    with open(config_hyperparams_file, 'r') as file:\n",
    "        config_hyperparams = yaml.safe_load(file)\n",
    "    \n",
    "    # Extract configuration parameters\n",
    "    setting_keys = 'seeds', 'test_seeds', 'problem_params', 'params_by_dataset', 'observation_params', 'store_params', 'warehouse_params', 'echelon_params', 'sample_data_params'\n",
    "    hyperparams_keys = 'trainer_params', 'optimizer_params', 'nn_params'\n",
    "    seeds, test_seeds, problem_params, params_by_dataset, observation_params, store_params, warehouse_params, echelon_params, sample_data_params = [\n",
    "        config_setting[key] for key in setting_keys\n",
    "    ]\n",
    "    \n",
    "    observation_params = DefaultDict(lambda: None, observation_params)\n",
    "    \n",
    "    # Load data files\n",
    "    print(\"Loading data files...\")\n",
    "    inventory_data = torch.load(inventory_state_path, map_location=device)\n",
    "    \n",
    "    # Load data files based on store_params configuration\n",
    "    data_files = {}\n",
    "    if 'demand' in store_params and 'file_location' in store_params['demand']:\n",
    "        data_files['demands'] = torch.load(data_dir + store_params['demand']['file_location'].split('/')[-1], map_location=device)\n",
    "    \n",
    "    if 'stockout' in store_params and 'file_location' in store_params['stockout']:\n",
    "        data_files['stockouts'] = torch.load(data_dir + store_params['stockout']['file_location'].split('/')[-1], map_location=device)\n",
    "    \n",
    "    # Load time features\n",
    "    if observation_params['time_features_file']:\n",
    "        date_features = pd.read_csv(data_dir + observation_params['time_features_file'].split('/')[-1])\n",
    "        # Create a mapping from feature names to column indices\n",
    "        feature_to_index = {}\n",
    "        for i, col in enumerate(date_features.columns):\n",
    "            if col != 'date':  # Skip the date column\n",
    "                feature_to_index[col] = i - 1  # Adjust for dropped date column\n",
    "        \n",
    "        # Create tensor with features in the order specified by config\n",
    "        if observation_params['time_features']:\n",
    "            ordered_features = []\n",
    "            for feature_name in observation_params['time_features']:\n",
    "                if feature_name in feature_to_index:\n",
    "                    col_idx = feature_to_index[feature_name]\n",
    "                    ordered_features.append(date_features.iloc[:, col_idx + 1].values)  # +1 because we skip date column\n",
    "                else:\n",
    "                    print(f\"Warning: Feature '{feature_name}' not found in date features\")\n",
    "                    ordered_features.append(np.zeros(len(date_features)))\n",
    "            \n",
    "            date_features_tensor = torch.tensor(np.column_stack(ordered_features), dtype=torch.float32).to(device)\n",
    "        else:\n",
    "            # Fallback to original method if no specific order is specified\n",
    "            date_features_tensor = torch.tensor(date_features.drop('date', axis=1).values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Load product features\n",
    "    if 'product_features' in store_params and 'file_location' in store_params['product_features']:\n",
    "        product_features = pd.read_csv(data_dir + store_params['product_features']['file_location'].split('/')[-1])\n",
    "        product_features_tensor = torch.tensor(product_features.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Determine time period\n",
    "    if time_period_idx is None:\n",
    "        # Use the last period\n",
    "        if 'demands' in data_files:\n",
    "            time_period_idx = data_files['demands'].shape[2] - 1\n",
    "        else:\n",
    "            time_period_idx = -1\n",
    "    \n",
    "    # Prepare past demands\n",
    "    if 'demands' in data_files and observation_params['demand']['past_periods'] > 0:\n",
    "        past_periods = observation_params['demand']['past_periods']\n",
    "        start_idx = max(0, time_period_idx - past_periods + 1)\n",
    "        past_demands = data_files['demands'][:, :, start_idx:time_period_idx+1]\n",
    "        # Pad with zeros if we don't have enough history\n",
    "        if past_demands.shape[2] < past_periods:\n",
    "            padding = torch.zeros(past_demands.shape[0], past_demands.shape[1], past_periods - past_demands.shape[2], device=device)\n",
    "            past_demands = torch.cat([padding, past_demands], dim=2)\n",
    "    \n",
    "    # Prepare past stockouts\n",
    "    if 'stockouts' in data_files and 'stockout' in observation_params and observation_params['stockout']['past_periods'] > 0:\n",
    "        past_periods = observation_params['stockout']['past_periods']\n",
    "        start_idx = max(0, time_period_idx - past_periods + 1)\n",
    "        past_stockouts = data_files['stockouts'][:, :, start_idx:time_period_idx+1]\n",
    "        # Pad with zeros if we don't have enough history\n",
    "        if past_stockouts.shape[2] < past_periods:\n",
    "            padding = torch.zeros(past_stockouts.shape[0], past_stockouts.shape[1], past_periods - past_stockouts.shape[2], device=device)\n",
    "            past_stockouts = torch.cat([padding, past_stockouts], dim=2)\n",
    "    \n",
    "    # Prepare time features for the current period\n",
    "    if observation_params['time_features']:\n",
    "        time_features_expanded = date_features_tensor[time_period_idx:time_period_idx+1].expand(inventory_data.shape[0], -1)\n",
    "    \n",
    "    # Prepare product features\n",
    "    if 'product_features' in store_params and 'features' in store_params['product_features']:\n",
    "        feature_indices = []\n",
    "        for feature in store_params['product_features']['features']:\n",
    "            if feature in product_features.columns:\n",
    "                feature_indices.append(product_features.columns.get_loc(feature))\n",
    "        product_features_subset = product_features_tensor[:, feature_indices]\n",
    "    \n",
    "    # Create static features from store_params\n",
    "    static_features = {}\n",
    "    if observation_params['include_static_features']:\n",
    "        for feature_name, include in observation_params['include_static_features'].items():\n",
    "            if include and feature_name in store_params:\n",
    "                if 'value' in store_params[feature_name]:\n",
    "                    value = store_params[feature_name]['value']\n",
    "                    static_features[feature_name] = torch.full(\n",
    "                        (inventory_data.shape[0], inventory_data.shape[1]), \n",
    "                        value, \n",
    "                        device=device\n",
    "                    )\n",
    "    \n",
    "    # Build observation dictionary\n",
    "    observation = {\n",
    "        'store_inventories': inventory_data,\n",
    "        'current_period': torch.tensor([time_period_idx], device=device),\n",
    "    }\n",
    "    \n",
    "    # Add past demands\n",
    "    if 'past_demands' in locals():\n",
    "        observation['past_demands'] = past_demands\n",
    "    \n",
    "    # Add past stockouts\n",
    "    if 'past_stockouts' in locals():\n",
    "        observation['past_stockouts'] = past_stockouts\n",
    "    \n",
    "    # Add product features\n",
    "    if 'product_features_subset' in locals():\n",
    "        observation['product_features'] = product_features_subset\n",
    "    \n",
    "    # Add static features\n",
    "    observation.update(static_features)\n",
    "    \n",
    "    # Add time features\n",
    "    if observation_params['time_features']:\n",
    "        for i, feature_name in enumerate(observation_params['time_features']):\n",
    "            if i < time_features_expanded.shape[1]:\n",
    "                observation[feature_name] = time_features_expanded[:, i:i+1]\n",
    "    \n",
    "    # Add internal data\n",
    "    internal_data = {}\n",
    "    if 'demands' in data_files:\n",
    "        internal_data['demands'] = data_files['demands']\n",
    "    if 'stockouts' in data_files:\n",
    "        internal_data['stockouts'] = data_files['stockouts']\n",
    "    \n",
    "    internal_data['period_shift'] = observation_params['demand'].get('period_shift', 0)\n",
    "    observation['internal_data'] = internal_data\n",
    "    \n",
    "    # Make prediction\n",
    "    print(\"Making prediction...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(observation)\n",
    "    \n",
    "    # Round predictions if requested\n",
    "    if round_predictions:\n",
    "        predictions['stores'] = torch.round(predictions['stores'])\n",
    "    \n",
    "    print(f\"Predictions shape: {predictions['stores'].shape}\")\n",
    "    print(f\"Sample predictions (first 10): {predictions['stores'][:10]}\")\n",
    "    print(f\"Mean of predictions: {predictions['stores'].mean()}\")\n",
    "    print(f\"Time period used: {time_period_idx}\")\n",
    "    print(f\"Predictions rounded: {round_predictions}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Convenience function using current session's config\n",
    "def make_predictions_with_current_model_general(model, device, round_predictions=True):\n",
    "    \"\"\"\n",
    "    Make predictions using the current session's configuration and model.\n",
    "    \"\"\"\n",
    "    return make_predictions_from_config(model, device, round_predictions=round_predictions)\n",
    "\n",
    "# Function to save predictions in submission format\n",
    "def save_predictions_to_submission_format(predictions, output_filename=\"predictions_submission.csv\", \n",
    "                                        reference_data_path=\"vn2_data/Week 0 - 2024-04-08 - Initial State.csv\"):\n",
    "    \"\"\"\n",
    "    Save model predictions in the submission template format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : dict\n",
    "        Dictionary containing model predictions with 'stores' key\n",
    "    output_filename : str\n",
    "        Name of the output CSV file\n",
    "    reference_data_path : str\n",
    "        Path to reference data file to get Store and Product mapping\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load reference data to get Store and Product mapping\n",
    "    print(f\"Loading reference data from {reference_data_path}...\")\n",
    "    reference_data = pd.read_csv(reference_data_path)\n",
    "    \n",
    "    # Extract Store and Product columns\n",
    "    store_product_mapping = reference_data[['Store', 'Product']].copy()\n",
    "    \n",
    "    # Get predictions tensor and convert to numpy\n",
    "    predictions_tensor = predictions['stores'].cpu().numpy()  # Convert to CPU numpy array\n",
    "    \n",
    "    # Flatten predictions to match the number of store-product combinations\n",
    "    # predictions_tensor shape is [batch_size, n_stores, n_warehouses]\n",
    "    # We need to flatten it to match the number of rows in reference data\n",
    "    if predictions_tensor.ndim == 3:\n",
    "        # If 3D, flatten the last two dimensions\n",
    "        predictions_flat = predictions_tensor.reshape(-1)\n",
    "    else:\n",
    "        # If already 2D or 1D, use as is\n",
    "        predictions_flat = predictions_tensor.flatten()\n",
    "    \n",
    "    # Ensure we have the right number of predictions\n",
    "    if len(predictions_flat) != len(store_product_mapping):\n",
    "        print(f\"Warning: Number of predictions ({len(predictions_flat)}) doesn't match number of store-product combinations ({len(store_product_mapping)})\")\n",
    "        # Truncate or pad as needed\n",
    "        if len(predictions_flat) > len(store_product_mapping):\n",
    "            predictions_flat = predictions_flat[:len(store_product_mapping)]\n",
    "        else:\n",
    "            # Pad with zeros if we have fewer predictions\n",
    "            padding = np.zeros(len(store_product_mapping) - len(predictions_flat))\n",
    "            predictions_flat = np.concatenate([predictions_flat, padding])\n",
    "    \n",
    "    # Add predictions to the dataframe\n",
    "    store_product_mapping['Prediction'] = predictions_flat.astype(int)\n",
    "    \n",
    "    # Save to CSV\n",
    "    print(f\"Saving predictions to {output_filename}...\")\n",
    "    store_product_mapping.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(store_product_mapping)} predictions to {output_filename}\")\n",
    "    print(f\"Sample predictions:\")\n",
    "    print(store_product_mapping.head(10))\n",
    "    print(f\"Prediction statistics:\")\n",
    "    print(f\"  Mean: {store_product_mapping['Prediction'].mean():.2f}\")\n",
    "    print(f\"  Min: {store_product_mapping['Prediction'].min()}\")\n",
    "    print(f\"  Max: {store_product_mapping['Prediction'].max()}\")\n",
    "    print(f\"  Non-zero predictions: {(store_product_mapping['Prediction'] > 0).sum()}\")\n",
    "    \n",
    "    return store_product_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inventory_state_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use with different config files\u001b[39;00m\n\u001b[1;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m make_predictions_from_config(\n\u001b[1;32m      3\u001b[0m     model, device,\n\u001b[1;32m      4\u001b[0m     config_setting_file\u001b[38;5;241m=\u001b[39mconfig_setting_file,\n\u001b[1;32m      5\u001b[0m     config_hyperparams_file\u001b[38;5;241m=\u001b[39mconfig_hyperparams_file,\n\u001b[0;32m----> 6\u001b[0m     inventory_state_path\u001b[38;5;241m=\u001b[39m\u001b[43minventory_state_path\u001b[49m,\n\u001b[1;32m      7\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# time_period_idx=100  # Use specific time period\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inventory_state_path' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to make predictions with the current trained model\n",
    "import numpy as np\n",
    "\n",
    "def make_predictions_with_current_model(model, device, round_predictions=True):\n",
    "    \"\"\"\n",
    "    Make predictions using the currently loaded model and your inventory state data.\n",
    "    This assumes the model is already trained and loaded in the current session.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The trained model\n",
    "    device : str\n",
    "        Device to run inference on\n",
    "    round_predictions : bool, optional\n",
    "        Whether to round predictions to the nearest integer. Default is True.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load your inventory state data\n",
    "    print(\"Loading inventory state data...\")\n",
    "    inventory_data = torch.load('vn2_processed_data/all_data/inventory_state.pt', map_location=device)\n",
    "    \n",
    "    # Load other required data files\n",
    "    sales_data = torch.load('vn2_processed_data/all_data/sales.pt', map_location=device)\n",
    "    stock_data = torch.load('vn2_processed_data/all_data/stock.pt', map_location=device)\n",
    "    time_product_data = torch.load('vn2_processed_data/all_data/time_product_features.pt', map_location=device)\n",
    "    \n",
    "    # Load CSV data\n",
    "    date_features = pd.read_csv('vn2_processed_data/all_data/date_features.csv')\n",
    "    product_features = pd.read_csv('vn2_processed_data/all_data/product_features.csv')\n",
    "    \n",
    "    # Convert CSV data to tensors with correct feature mapping\n",
    "    # Create a mapping from feature names to column indices\n",
    "    feature_to_index = {}\n",
    "    for i, col in enumerate(date_features.columns):\n",
    "        if col != 'date':  # Skip the date column\n",
    "            feature_to_index[col] = i - 1  # Adjust for dropped date column\n",
    "    \n",
    "    # Create tensor with features in the order specified by config\n",
    "    ordered_features = []\n",
    "    config_time_features = ['days_from_christmas', 'day_of_month', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n",
    "    for feature_name in config_time_features:\n",
    "        if feature_name in feature_to_index:\n",
    "            col_idx = feature_to_index[feature_name]\n",
    "            ordered_features.append(date_features.iloc[:, col_idx + 1].values)  # +1 because we skip date column\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{feature_name}' not found in date features\")\n",
    "            ordered_features.append(np.zeros(len(date_features)))\n",
    "    \n",
    "    date_features_tensor = torch.tensor(np.column_stack(ordered_features), dtype=torch.float32).to(device)\n",
    "    product_features_tensor = torch.tensor(product_features.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Prepare observation data for the last time period\n",
    "    # The model expects 16 past periods, so we'll use the last 16 periods\n",
    "    past_periods = 16\n",
    "    last_period_idx = -past_periods  # Start from 16 periods ago\n",
    "    \n",
    "    # Prepare past demands (16 periods)\n",
    "    past_demands = sales_data[:, :, last_period_idx:]  # Shape: [599, 1, 16]\n",
    "    \n",
    "    # Prepare past stockouts (16 periods) - assuming stockouts are derived from stock data\n",
    "    past_stockouts = stock_data[:, :, last_period_idx:]  # Shape: [599, 1, 16]\n",
    "    \n",
    "    # Prepare time features for the last period\n",
    "    last_period_time_features = date_features_tensor[-1:]  # Shape: [1, 16] (last row)\n",
    "    # Expand to match batch size\n",
    "    time_features_expanded = last_period_time_features.expand(inventory_data.shape[0], -1)  # Shape: [599, 16]\n",
    "    \n",
    "    # Prepare product features (only Store and Product as specified in config)\n",
    "    product_features_subset = product_features_tensor[:, :2]  # Only first 2 columns: Store, Product\n",
    "    \n",
    "    # Create static features (these are constant across all samples based on config)\n",
    "    holding_costs = torch.full((inventory_data.shape[0], inventory_data.shape[1]), 0.2, device=device)  # [599, 1]\n",
    "    underage_costs = torch.full((inventory_data.shape[0], inventory_data.shape[1]), 1.0, device=device)  # [599, 1]\n",
    "    lead_times = torch.full((inventory_data.shape[0], inventory_data.shape[1]), 2, device=device)  # [599, 1]\n",
    "    \n",
    "    observation = {\n",
    "        'store_inventories': inventory_data,  # [599, 1, 2] - use actual inventory data\n",
    "        'past_demands': past_demands,  # [599, 1, 16]\n",
    "        'past_stockouts': past_stockouts,  # [599, 1, 16]\n",
    "        'product_features': product_features_subset,  # [599, 2] - only Store and Product\n",
    "        'holding_costs': holding_costs,  # [599, 1] - static feature\n",
    "        'underage_costs': underage_costs,  # [599, 1] - static feature\n",
    "        'lead_times': lead_times,  # [599, 1] - static feature\n",
    "        'days_from_christmas': time_features_expanded[:, 0:1],  # [599, 1] - index 0\n",
    "        'day_of_month': time_features_expanded[:, 1:2],  # [599, 1] - index 1\n",
    "        'month_1': time_features_expanded[:, 2:3],  # [599, 1] - index 2\n",
    "        'month_2': time_features_expanded[:, 3:4],  # [599, 1] - index 3\n",
    "        'month_3': time_features_expanded[:, 4:5],  # [599, 1] - index 4\n",
    "        'month_4': time_features_expanded[:, 5:6],  # [599, 1] - index 5\n",
    "        'month_5': time_features_expanded[:, 6:7],  # [599, 1] - index 6\n",
    "        'month_6': time_features_expanded[:, 7:8],  # [599, 1] - index 7\n",
    "        'month_7': time_features_expanded[:, 8:9],  # [599, 1] - index 8\n",
    "        'month_8': time_features_expanded[:, 9:10],  # [599, 1] - index 9\n",
    "        'month_9': time_features_expanded[:, 10:11],  # [599, 1] - index 10\n",
    "        'month_10': time_features_expanded[:, 11:12],  # [599, 1] - index 11\n",
    "        'month_11': time_features_expanded[:, 12:13],  # [599, 1] - index 12\n",
    "        'month_12': time_features_expanded[:, 13:14],  # [599, 1] - index 13\n",
    "        'current_period': torch.tensor([last_period_idx], device=device),\n",
    "    }\n",
    "\n",
    "    # print(f'observation: {observation[\"month_12\"]}')\n",
    "    # Add internal data (using the same structure as in training)\n",
    "    internal_data = {\n",
    "        'demands': sales_data,\n",
    "        'period_shift': 0,  # Adjust as needed\n",
    "    }\n",
    "    \n",
    "    observation['internal_data'] = internal_data\n",
    "    \n",
    "    # Make prediction using the current model\n",
    "    print(\"Making prediction...\")\n",
    "    model.eval()  # Set to evaluation mode  \n",
    "    with torch.no_grad():\n",
    "        predictions = model(observation)\n",
    "    \n",
    "    # Round predictions if requested\n",
    "    if round_predictions:\n",
    "        predictions['stores'] = torch.round(predictions['stores'])\n",
    "    \n",
    "    print(f\"Predictions shape: {predictions['stores'].shape}\")\n",
    "    print(f\"Sample predictions (first 10): {predictions['stores'][:10]}\")\n",
    "    print(f\"Mean of predictions: {predictions['stores'].mean()}\")\n",
    "    print(f\"Predictions rounded: {round_predictions}\")\n",
    "    print(f\"Past stockouts: {past_stockouts[:10]}\")\n",
    "    print(f\"Past demands: {past_demands[:10]}\")\n",
    "    print(f\"Inventory data: {observation['store_inventories'][:10]}\")\n",
    "    print(f\"Holding costs: {observation['holding_costs'][:10]}\")\n",
    "    print(f\"Underage costs: {observation['underage_costs'][:10]}\")\n",
    "    print(f\"Lead times: {observation['lead_times'][:10]}\")\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the config files\n",
    "In this example, we will apply a Vanilla Neural Network to a setting of one store under a lost demand assumption.\n",
    "Go to the respective config files to change the hyperparameters of the neural network or the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_setting_file = 'config_files/settings/vn2_round_1.yml'\n",
    "# config_setting_file = 'config_files/settings/one_store_lost.yml'\n",
    "config_hyperparams_file = 'config_files/policies_and_hyperparams/data_driven_net.yml'\n",
    "# config_hyperparams_file = 'config_files/policies_and_hyperparams/vanilla_one_store.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/ma4177/Neural_inventory_control/data_handling.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(demand)\n"
     ]
    }
   ],
   "source": [
    "with open(config_setting_file, 'r') as file:\n",
    "    config_setting = yaml.safe_load(file)\n",
    "\n",
    "with open(config_hyperparams_file, 'r') as file:\n",
    "    config_hyperparams = yaml.safe_load(file)\n",
    "\n",
    "setting_keys = 'seeds', 'test_seeds', 'problem_params', 'params_by_dataset', 'observation_params', 'store_params', 'warehouse_params', 'echelon_params', 'sample_data_params'\n",
    "hyperparams_keys = 'trainer_params', 'optimizer_params', 'nn_params'\n",
    "seeds, test_seeds, problem_params, params_by_dataset, observation_params, store_params, warehouse_params, echelon_params, sample_data_params = [\n",
    "    config_setting[key] for key in setting_keys\n",
    "    ]\n",
    "\n",
    "trainer_params, optimizer_params, nn_params = [config_hyperparams[key] for key in hyperparams_keys]\n",
    "observation_params = DefaultDict(lambda: None, observation_params)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_creator = DatasetCreator()\n",
    "\n",
    "# For realistic data, train, dev and test sets correspond to the same products, but over disjoint periods.\n",
    "# We will therefore create one scenario, and then split the data into train, dev and test sets by \n",
    "# \"copying\" all non-period related information, and then splitting the period related information\n",
    "if sample_data_params['split_by_period']:\n",
    "    \n",
    "    scenario = Scenario(\n",
    "        periods=None,  # period info for each dataset is given in sample_data_params\n",
    "        problem_params=problem_params, \n",
    "        store_params=store_params, \n",
    "        warehouse_params=warehouse_params, \n",
    "        echelon_params=echelon_params, \n",
    "        num_samples=params_by_dataset['train']['n_samples'],  # in this case, num_samples=number of products, which has to be the same across all datasets\n",
    "        observation_params=observation_params, \n",
    "        seeds=seeds\n",
    "        )\n",
    "    \n",
    "    train_dataset, dev_dataset, test_dataset = dataset_creator.create_datasets(\n",
    "        scenario, \n",
    "        split=True, \n",
    "        by_period=True, \n",
    "        periods_for_split=[sample_data_params[k] for  k in ['train_periods', 'dev_periods', 'test_periods']],)\n",
    "\n",
    "# For synthetic data, we will first create a scenario that we will divide into train and dev sets by sample index.\n",
    "# Then, we will create a separate scenario for the test set, which will be exaclty the same as the previous scenario, \n",
    "# but with different seeds to generate demand traces, and with a longer time horizon.\n",
    "# One can use this method of generating scenarios to train a model using some specific problem primitives, \n",
    "# and then test it on a different set of problem primitives, by simply creating a new scenario with the desired primitives.\n",
    "else:\n",
    "    max_periods = max(params_by_dataset['train']['periods'], params_by_dataset['dev']['periods'])\n",
    "    scenario = Scenario(\n",
    "        periods=max_periods, \n",
    "        # periods=params_by_dataset['train']['periods'], \n",
    "        problem_params=problem_params, \n",
    "        store_params=store_params, \n",
    "        warehouse_params=warehouse_params, \n",
    "        echelon_params=echelon_params, \n",
    "        num_samples=params_by_dataset['train']['n_samples'] + params_by_dataset['dev']['n_samples'], \n",
    "        observation_params=observation_params, \n",
    "        seeds=seeds\n",
    "        )\n",
    "\n",
    "    train_dataset, dev_dataset = dataset_creator.create_datasets(scenario, split=True, by_sample_indexes=True, sample_index_for_split=params_by_dataset['dev']['n_samples'])\n",
    "\n",
    "    scenario = Scenario(\n",
    "        params_by_dataset['test']['periods'], \n",
    "        problem_params, \n",
    "        store_params, \n",
    "        warehouse_params, \n",
    "        echelon_params, \n",
    "        params_by_dataset['test']['n_samples'], \n",
    "        observation_params, \n",
    "        test_seeds\n",
    "        )\n",
    "\n",
    "    test_dataset = dataset_creator.create_datasets(scenario, split=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=params_by_dataset['train']['batch_size'], shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=params_by_dataset['dev']['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params_by_dataset['test']['batch_size'], shuffle=False)\n",
    "data_loaders = {'train': train_loader, 'dev': dev_loader, 'test': test_loader}\n",
    "\n",
    "neural_net_creator = NeuralNetworkCreator\n",
    "model = neural_net_creator().create_neural_network(scenario, nn_params, device=device)\n",
    "\n",
    "loss_function = PolicyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=optimizer_params['learning_rate'])\n",
    "\n",
    "simulator = Simulator(device=device)\n",
    "trainer = Trainer(device=device)\n",
    "\n",
    "# We will create a folder for each day of the year, and a subfolder for each model\n",
    "# When executing with different problem primitives (i.e. instance), it might be useful to create an additional subfolder for each instance\n",
    "trainer_params['base_dir'] = 'saved_models'\n",
    "trainer_params['save_model_folders'] = [trainer.get_year_month_day(), nn_params['name']]\n",
    "\n",
    "# We will simply name the model with the current time stamp\n",
    "trainer_params['save_model_filename'] = trainer.get_time_stamp()\n",
    "\n",
    "# Load previous model if load_model is set to True in the config file\n",
    "if trainer_params['load_previous_model']:\n",
    "    print(f'Loading model from {trainer_params[\"load_model_path\"]}')\n",
    "    model, optimizer = trainer.load_model(model, optimizer, trainer_params['load_model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['underage_costs', 'holding_costs', 'lead_times', 'initial_inventories', 'product_features', 'demands', 'stockouts', 'days_from_christmas', 'day_of_month', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12'])\n",
      "torch.Size([599, 2])\n",
      "torch.Size([599, 1, 53])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.data.keys())\n",
    "print(train_loader.dataset.data['product_features'].shape)\n",
    "print(dev_loader.dataset.data['day_of_month'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: load a model to continue training\n",
    "load_model = False\n",
    "if load_model:\n",
    "    model_filename = \"saved_models/2025_10_04/model_1.pt\"\n",
    "    model, optimizer = trainer.load_model(model, optimizer, model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Average per-period train loss: 0.03868479784694761\n",
      "Average per-period dev loss: 0.0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 2\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 3\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 4\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 5\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 6\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 7\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 8\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 9\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 10\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 11\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0.0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 12\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 13\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 14\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 15\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 16\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 17\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 18\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n",
      "epoch: 19\n",
      "Average per-period train loss: 0.0\n",
      "Average per-period dev loss: 0\n",
      "Best per-period dev loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    trainer_params['epochs'], \n",
    "    loss_function, simulator, \n",
    "    model, \n",
    "    data_loaders, \n",
    "    optimizer, \n",
    "    problem_params, \n",
    "    observation_params, \n",
    "    params_by_dataset, \n",
    "    trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional:Save the trained model\n",
    "save_model = False\n",
    "if save_model:\n",
    "    # The function will save the model that achieved the smallest dev_loss during training\n",
    "    model_filename = \"model_32_demands\"\n",
    "    saved_model_path = save_trained_model(model_filename, trainer, optimizer, config_setting, config_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the losses\n",
    "ymin, ymax = 0, 5  # set the y-axis limit for the plot\n",
    "trainer.plot_losses(ymin=ymin, ymax=ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from saved_models/2025_10_04/model_1.pt\n"
     ]
    }
   ],
   "source": [
    "load_model_for_test = True\n",
    "if load_model_for_test:\n",
    "    model_filename = \"saved_models/2025_10_04/model_1.pt\"\n",
    "    model, optimizer = trainer.load_model(model, optimizer, model_filename)\n",
    "    print(f\"Loaded model from {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_test_loss, average_test_loss_to_report = trainer.test(\n",
    "    loss_function, \n",
    "    simulator, \n",
    "    model, \n",
    "    data_loaders, \n",
    "    optimizer, \n",
    "    problem_params, \n",
    "    observation_params, \n",
    "    params_by_dataset, \n",
    "    discrete_allocation=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating JustInTime model for comparison...\n",
      "Evaluating JustInTime model...\n",
      "JustInTime Average per-period test loss: -3.293201086778618\n"
     ]
    }
   ],
   "source": [
    "# Create and evaluate JustInTime model for comparison\n",
    "print(\"Creating JustInTime model for comparison...\")\n",
    "\n",
    "# Create JustInTime model with the same scenario and parameters\n",
    "justintime_nn_params = {\n",
    "    'name': 'just_in_time',\n",
    "    'inner_layer_activations': {'master': 'relu'},\n",
    "    'output_layer_activation': {'master': None},\n",
    "    'neurons_per_hidden_layer': {'master': []},\n",
    "    'output_sizes': {'master': None},\n",
    "    'initial_bias': {'master': None}\n",
    "}\n",
    "\n",
    "justintime_model = NeuralNetworkCreator().create_neural_network(scenario, justintime_nn_params, device=device)\n",
    "\n",
    "# Evaluate JustInTime model\n",
    "print(\"Evaluating JustInTime model...\")\n",
    "justintime_test_loss, justintime_test_loss_to_report = trainer.test(\n",
    "    loss_function, \n",
    "    simulator, \n",
    "    justintime_model, \n",
    "    data_loaders, \n",
    "    optimizer, \n",
    "    problem_params, \n",
    "    observation_params, \n",
    "    params_by_dataset, \n",
    "    discrete_allocation=True\n",
    ")\n",
    "\n",
    "print(f'JustInTime Average per-period test loss: {justintime_test_loss_to_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "============================================================\n",
      "Trained Model Test Loss:     -1.864408\n",
      "JustInTime Model Test Loss:  -3.293201\n",
      "Difference:                  1.428793\n",
      " JustInTime performs BETTER than trained model (lower loss)\n",
      "  Fraction of JustInTime loss: 56.61%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Print comparison between models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Trained Model Test Loss:     {average_test_loss_to_report:.6f}\")\n",
    "print(f\"JustInTime Model Test Loss:  {justintime_test_loss_to_report:.6f}\")\n",
    "print(f\"Difference:                  {average_test_loss_to_report - justintime_test_loss_to_report:.6f}\")\n",
    "\n",
    "if average_test_loss_to_report < justintime_test_loss_to_report:\n",
    "    print(\" Trained model performs BETTER than JustInTime (lower loss)\")\n",
    "    improvement = ((justintime_test_loss_to_report - average_test_loss_to_report) / abs(justintime_test_loss_to_report)) * 100\n",
    "    print(f\"  Improvement: {improvement:.2f}%\")\n",
    "else:\n",
    "    print(\" JustInTime performs BETTER than trained model (lower loss)\")\n",
    "    gap = ((average_test_loss_to_report) / justintime_test_loss_to_report) * 100\n",
    "    print(f\"  Fraction of JustInTime loss: {gap:.2f}%\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average per-period test loss: -1.8661362943549706\n"
     ]
    }
   ],
   "source": [
    "print(f'Average per-period test loss: {average_test_loss_to_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration files...\n",
      "Loading data files...\n",
      "Making prediction...\n",
      "Predictions shape: torch.Size([599, 1, 1])\n",
      "Sample predictions (first 10): tensor([[[ 1.]],\n",
      "\n",
      "        [[ 1.]],\n",
      "\n",
      "        [[10.]],\n",
      "\n",
      "        [[ 6.]],\n",
      "\n",
      "        [[ 2.]],\n",
      "\n",
      "        [[ 2.]],\n",
      "\n",
      "        [[12.]],\n",
      "\n",
      "        [[ 1.]],\n",
      "\n",
      "        [[ 3.]],\n",
      "\n",
      "        [[ 7.]]], device='cuda:0')\n",
      "Mean of predictions: 2.6193654537200928\n",
      "Time period used: 156\n",
      "Predictions rounded: True\n",
      "Loading reference data from vn2_data/Week 0 - 2024-04-08 - Initial State.csv...\n",
      "Saving predictions to predictions/submission.csv...\n",
      "Saved 599 predictions to predictions/submission.csv\n",
      "Sample predictions:\n",
      "   Store  Product  Prediction\n",
      "0      0      126           1\n",
      "1      0      182           1\n",
      "2      1      124          10\n",
      "3      2      124           6\n",
      "4      2      126           2\n",
      "5      3      126           2\n",
      "6      4      124          12\n",
      "7      4      126           1\n",
      "8      5      126           3\n",
      "9      6      124           7\n",
      "Prediction statistics:\n",
      "  Mean: 2.62\n",
      "  Min: 0\n",
      "  Max: 80\n",
      "  Non-zero predictions: 531\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Product</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>64</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>64</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>65</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>66</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>66</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Store  Product  Prediction\n",
       "0        0      126           1\n",
       "1        0      182           1\n",
       "2        1      124          10\n",
       "3        2      124           6\n",
       "4        2      126           2\n",
       "..     ...      ...         ...\n",
       "594     64      193           1\n",
       "595     64      238           1\n",
       "596     65      126           2\n",
       "597     66      124           5\n",
       "598     66      126           1\n",
       "\n",
       "[599 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use with different config files\n",
    "predictions = make_predictions_from_config(\n",
    "    model, device,\n",
    "    config_setting_file=config_setting_file,\n",
    "    config_hyperparams_file=config_hyperparams_file,\n",
    "    inventory_state_path='vn2_processed_data/all_data/inventory_state.pt',\n",
    "    data_dir='vn2_processed_data/all_data/',\n",
    "    round_predictions=True\n",
    ")\n",
    "\n",
    "save_predictions_to_submission_format(predictions, output_filename=\"predictions/submission.csv\", reference_data_path=\"vn2_data/Week 0 - 2024-04-08 - Initial State.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions with current model...\n",
      "Loading inventory state data...\n",
      "Making prediction...\n",
      "Predictions shape: torch.Size([599, 1, 1])\n",
      "Sample predictions (first 10): tensor([[[ 0.5762]],\n",
      "\n",
      "        [[ 1.3479]],\n",
      "\n",
      "        [[ 9.6040]],\n",
      "\n",
      "        [[ 5.8701]],\n",
      "\n",
      "        [[ 2.0314]],\n",
      "\n",
      "        [[ 2.4411]],\n",
      "\n",
      "        [[11.7404]],\n",
      "\n",
      "        [[ 0.5272]],\n",
      "\n",
      "        [[ 2.7196]],\n",
      "\n",
      "        [[ 7.1262]]], device='cuda:0')\n",
      "Mean of predictions: 2.585651397705078\n",
      "Past stockouts: tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "       device='cuda:0')\n",
      "Past demands: tensor([[[ 0.,  0.,  2.,  2.,  0.,  0.,  0.,  2.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
      "           2.,  2.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  3.,\n",
      "           1.,  1.]],\n",
      "\n",
      "        [[ 7., 10.,  5., 11.,  7., 13.,  8., 17.,  6., 11.,  8., 12.,  6.,  7.,\n",
      "           9.,  7.]],\n",
      "\n",
      "        [[ 4.,  8.,  6.,  7.,  9.,  7.,  6.,  8.,  8., 18., 11., 14.,  3., 12.,\n",
      "          13.,  2.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  2.,  5.,  2.,  2.,  4.,  2.,\n",
      "           3.,  2.]],\n",
      "\n",
      "        [[27.,  0.,  0.,  0.,  2.,  0.,  0.,  2.,  3.,  0.,  0.,  0.,  0.,  2.,\n",
      "           0.,  0.]],\n",
      "\n",
      "        [[17.,  6., 11., 15., 12., 11.,  9., 13., 13., 15.,  5., 13.,  8.,  6.,\n",
      "           7., 12.]],\n",
      "\n",
      "        [[ 3.,  2.,  0.,  0.,  0.,  2.,  2.,  0.,  0.,  0.,  0.,  2.,  2.,  0.,\n",
      "           0.,  0.]],\n",
      "\n",
      "        [[16.,  0., 15.,  0.,  0.,  0.,  2.,  0., 10.,  2.,  0.,  0., 17.,  0.,\n",
      "           0.,  0.]],\n",
      "\n",
      "        [[ 1.,  4.,  2.,  0.,  4.,  7., 12.,  8.,  4.,  7., 10.,  9.,  6.,  6.,\n",
      "          10.,  7.]]], device='cuda:0')\n",
      "Inventory data: tensor([[[ 3.,  3.]],\n",
      "\n",
      "        [[ 1.,  1.]],\n",
      "\n",
      "        [[ 6.,  6.]],\n",
      "\n",
      "        [[ 9.,  7.]],\n",
      "\n",
      "        [[ 3.,  1.]],\n",
      "\n",
      "        [[ 4.,  2.]],\n",
      "\n",
      "        [[11., 10.]],\n",
      "\n",
      "        [[ 2.,  1.]],\n",
      "\n",
      "        [[ 4.,  4.]],\n",
      "\n",
      "        [[ 7.,  7.]]], device='cuda:0')\n",
      "Holding costs: tensor([[0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000]], device='cuda:0')\n",
      "Underage costs: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0')\n",
      "Lead times: tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Run the prediction\n",
    "print(\"Making predictions with current model...\")\n",
    "predictions = make_predictions_with_current_model(model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
