{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from trainer import *\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_state(model, trainer, optimizer, config_setting, config_hyperparams):\n",
    "    \"\"\"\n",
    "    Get the model state dictionary with the best weights (smallest dev_loss).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The model instance\n",
    "    trainer : Trainer\n",
    "        The trainer instance containing best performance data\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer instance\n",
    "    config_setting : dict\n",
    "        Configuration dictionary for settings\n",
    "    config_hyperparams : dict\n",
    "        Configuration dictionary for hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing all model information and best weights\n",
    "    \"\"\"\n",
    "    model_state = {\n",
    "        'epoch': trainer.best_epoch,\n",
    "        'model_state_dict': trainer.best_performance_data['model_params_to_save'],\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_train_loss': trainer.best_performance_data['train_loss'],\n",
    "        'best_dev_loss': trainer.best_performance_data['dev_loss'],\n",
    "        'all_train_losses': trainer.all_train_losses,\n",
    "        'all_dev_losses': trainer.all_dev_losses,\n",
    "        'all_test_losses': trainer.all_test_losses,\n",
    "        'warehouse_upper_bound': model.warehouse_upper_bound,\n",
    "        'config_setting': config_setting,\n",
    "        'config_hyperparams': config_hyperparams,\n",
    "        'save_timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return model_state\n",
    "\n",
    "\n",
    "def save_trained_model(filename, model, trainer, optimizer, config_setting, config_hyperparams):\n",
    "    \"\"\"\n",
    "    Save the trained model that achieved the smallest dev_loss.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : str\n",
    "        The filename to save the model as (without extension)\n",
    "    model : torch.nn.Module\n",
    "        The model instance\n",
    "    trainer : Trainer\n",
    "        The trainer instance containing best performance data\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer instance\n",
    "    config_setting : dict\n",
    "        Configuration dictionary for settings\n",
    "    config_hyperparams : dict\n",
    "        Configuration dictionary for hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The full path where the model was saved\n",
    "    \"\"\"\n",
    "    # Get the best model state\n",
    "    model_state = get_best_model_state(model, trainer, optimizer, config_setting, config_hyperparams)\n",
    "    \n",
    "    # Get today's date in YYYY_MM_DD format\n",
    "    today = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "    \n",
    "    # Create the directory structure: saved_models/{today's date}/\n",
    "    save_dir = f\"saved_models/{today}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the full path\n",
    "    model_path = f\"{save_dir}/{filename}.pt\"\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model_state, model_path)\n",
    "    \n",
    "    print(f\"Model saved successfully!\")\n",
    "    print(f\"Path: {model_path}\")\n",
    "    print(f\"Best dev loss: {trainer.best_performance_data['dev_loss']:.6f}\")\n",
    "    print(f\"Best epoch: {trainer.best_epoch + 1}\")\n",
    "    \n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_from_config(model, device, config_setting_file=None, config_hyperparams_file=None, \n",
    "                                inventory_state_path=None, data_dir=None, time_period_idx=None, round_predictions=True):\n",
    "    \"\"\"\n",
    "    Make predictions using a trained model by reading configuration files and automatically\n",
    "    building the observation data structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The trained model\n",
    "    device : str\n",
    "        Device to run inference on\n",
    "    config_setting_file : str, optional\n",
    "        Path to settings config file. If None, uses the current config files from the session.\n",
    "    config_hyperparams_file : str, optional  \n",
    "        Path to hyperparams config file. If None, uses the current config files from the session.\n",
    "    inventory_state_path : str, optional\n",
    "        Path to inventory state file. If None, uses default path.\n",
    "    data_dir : str, optional\n",
    "        Directory containing data files. If None, uses default path.\n",
    "    time_period_idx : int, optional\n",
    "        Time period index to use for prediction. If None, uses the last period.\n",
    "    round_predictions : bool, optional\n",
    "        Whether to round predictions to the nearest integer. Default is True.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : dict\n",
    "        Dictionary containing model predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use current config if not provided\n",
    "    if config_setting_file is None:\n",
    "        config_setting_file = 'config_files/settings/vn2_round_1.yml'\n",
    "    if config_hyperparams_file is None:\n",
    "        config_hyperparams_file = 'config_files/policies_and_hyperparams/data_driven_net.yml'\n",
    "    if inventory_state_path is None:\n",
    "        inventory_state_path = 'vn2_processed_data/all_data/inventory_state.pt'\n",
    "    if data_dir is None:\n",
    "        data_dir = 'vn2_processed_data/all_data/'\n",
    "    \n",
    "    # Load configuration files\n",
    "    print(\"Loading configuration files...\")\n",
    "    with open(config_setting_file, 'r') as file:\n",
    "        config_setting = yaml.safe_load(file)\n",
    "    \n",
    "    with open(config_hyperparams_file, 'r') as file:\n",
    "        config_hyperparams = yaml.safe_load(file)\n",
    "    \n",
    "    # Extract configuration parameters\n",
    "    setting_keys = 'seeds', 'test_seeds', 'problem_params', 'params_by_dataset', 'observation_params', 'store_params', 'warehouse_params', 'echelon_params', 'sample_data_params'\n",
    "    hyperparams_keys = 'trainer_params', 'optimizer_params', 'nn_params'\n",
    "    seeds, test_seeds, problem_params, params_by_dataset, observation_params, store_params, warehouse_params, echelon_params, sample_data_params = [\n",
    "        config_setting[key] for key in setting_keys\n",
    "    ]\n",
    "    \n",
    "    observation_params = DefaultDict(lambda: None, observation_params)\n",
    "    \n",
    "    # Load data files\n",
    "    print(\"Loading data files...\")\n",
    "    inventory_data = torch.load(inventory_state_path, map_location=device)\n",
    "    \n",
    "    # Load data files based on store_params configuration\n",
    "    data_files = {}\n",
    "    if 'demand' in store_params and 'file_location' in store_params['demand']:\n",
    "        data_files['demands'] = torch.load(data_dir + store_params['demand']['file_location'].split('/')[-1], map_location=device)\n",
    "    \n",
    "    if 'stockout' in store_params and 'file_location' in store_params['stockout']:\n",
    "        data_files['stockouts'] = torch.load(data_dir + store_params['stockout']['file_location'].split('/')[-1], map_location=device)\n",
    "    \n",
    "    # Load time features\n",
    "    if observation_params['time_features_file']:\n",
    "        date_features = pd.read_csv(data_dir + observation_params['time_features_file'].split('/')[-1])\n",
    "        # Create a mapping from feature names to column indices\n",
    "        feature_to_index = {}\n",
    "        for i, col in enumerate(date_features.columns):\n",
    "            if col != 'date':  # Skip the date column\n",
    "                feature_to_index[col] = i - 1  # Adjust for dropped date column\n",
    "        \n",
    "        # Create tensor with features in the order specified by config\n",
    "        if observation_params['time_features']:\n",
    "            ordered_features = []\n",
    "            for feature_name in observation_params['time_features']:\n",
    "                if feature_name in feature_to_index:\n",
    "                    col_idx = feature_to_index[feature_name]\n",
    "                    ordered_features.append(date_features.iloc[:, col_idx + 1].values)  # +1 because we skip date column\n",
    "                else:\n",
    "                    print(f\"Warning: Feature '{feature_name}' not found in date features\")\n",
    "                    ordered_features.append(np.zeros(len(date_features)))\n",
    "            \n",
    "            date_features_tensor = torch.tensor(np.column_stack(ordered_features), dtype=torch.float32).to(device)\n",
    "        else:\n",
    "            # Fallback to original method if no specific order is specified\n",
    "            date_features_tensor = torch.tensor(date_features.drop('date', axis=1).values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Load product features\n",
    "    if 'product_features' in store_params and 'file_location' in store_params['product_features']:\n",
    "        product_features = pd.read_csv(data_dir + store_params['product_features']['file_location'].split('/')[-1])\n",
    "        product_features_tensor = torch.tensor(product_features.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Determine time period\n",
    "    if time_period_idx is None:\n",
    "        # Use the last period\n",
    "        if 'demands' in data_files:\n",
    "            time_period_idx = data_files['demands'].shape[2] - 1\n",
    "        else:\n",
    "            time_period_idx = -1\n",
    "    \n",
    "    # Prepare past demands\n",
    "    if 'demands' in data_files and observation_params['demand']['past_periods'] > 0:\n",
    "        past_periods = observation_params['demand']['past_periods']\n",
    "        start_idx = max(0, time_period_idx - past_periods + 1)\n",
    "        past_demands = data_files['demands'][:, :, start_idx:time_period_idx+1]\n",
    "        # Pad with zeros if we don't have enough history\n",
    "        if past_demands.shape[2] < past_periods:\n",
    "            padding = torch.zeros(past_demands.shape[0], past_demands.shape[1], past_periods - past_demands.shape[2], device=device)\n",
    "            past_demands = torch.cat([padding, past_demands], dim=2)\n",
    "    \n",
    "    # Prepare past stockouts\n",
    "    if 'stockouts' in data_files and 'stockout' in observation_params and observation_params['stockout']['past_periods'] > 0:\n",
    "        past_periods = observation_params['stockout']['past_periods']\n",
    "        start_idx = max(0, time_period_idx - past_periods + 1)\n",
    "        past_stockouts = data_files['stockouts'][:, :, start_idx:time_period_idx+1]\n",
    "        # Pad with zeros if we don't have enough history\n",
    "        if past_stockouts.shape[2] < past_periods:\n",
    "            padding = torch.zeros(past_stockouts.shape[0], past_stockouts.shape[1], past_periods - past_stockouts.shape[2], device=device)\n",
    "            past_stockouts = torch.cat([padding, past_stockouts], dim=2)\n",
    "    \n",
    "    # Prepare time features for the current period\n",
    "    if observation_params['time_features']:\n",
    "        time_features_expanded = date_features_tensor[time_period_idx:time_period_idx+1].expand(inventory_data.shape[0], -1)\n",
    "    \n",
    "    # Prepare product features\n",
    "    if 'product_features' in store_params and 'features' in store_params['product_features']:\n",
    "        feature_indices = []\n",
    "        for feature in store_params['product_features']['features']:\n",
    "            if feature in product_features.columns:\n",
    "                feature_indices.append(product_features.columns.get_loc(feature))\n",
    "        product_features_subset = product_features_tensor[:, feature_indices]\n",
    "    \n",
    "    # Create static features from store_params\n",
    "    static_features = {}\n",
    "    if observation_params['include_static_features']:\n",
    "        for feature_name, include in observation_params['include_static_features'].items():\n",
    "            if include and feature_name in store_params:\n",
    "                if 'value' in store_params[feature_name]:\n",
    "                    value = store_params[feature_name]['value']\n",
    "                    static_features[feature_name] = torch.full(\n",
    "                        (inventory_data.shape[0], inventory_data.shape[1]), \n",
    "                        value, \n",
    "                        device=device\n",
    "                    )\n",
    "    \n",
    "    # Build observation dictionary\n",
    "    observation = {\n",
    "        'store_inventories': inventory_data,\n",
    "        'current_period': torch.tensor([time_period_idx], device=device),\n",
    "    }\n",
    "    \n",
    "    # Add past demands\n",
    "    if 'past_demands' in locals():\n",
    "        observation['past_demands'] = past_demands\n",
    "    \n",
    "    # Add past stockouts\n",
    "    if 'past_stockouts' in locals():\n",
    "        observation['past_stockouts'] = past_stockouts\n",
    "    \n",
    "    # Add product features\n",
    "    if 'product_features_subset' in locals():\n",
    "        observation['product_features'] = product_features_subset\n",
    "    \n",
    "    # Add static features\n",
    "    observation.update(static_features)\n",
    "    \n",
    "    # Add time features\n",
    "    if observation_params['time_features']:\n",
    "        for i, feature_name in enumerate(observation_params['time_features']):\n",
    "            if i < time_features_expanded.shape[1]:\n",
    "                observation[feature_name] = time_features_expanded[:, i:i+1]\n",
    "    \n",
    "    # Add internal data\n",
    "    internal_data = {}\n",
    "    if 'demands' in data_files:\n",
    "        internal_data['demands'] = data_files['demands']\n",
    "    if 'stockouts' in data_files:\n",
    "        internal_data['stockouts'] = data_files['stockouts']\n",
    "    \n",
    "    internal_data['period_shift'] = observation_params['demand'].get('period_shift', 0)\n",
    "    observation['internal_data'] = internal_data\n",
    "    \n",
    "    # Make prediction\n",
    "    print(\"Making prediction...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(observation)\n",
    "    \n",
    "    # Round predictions if requested\n",
    "    if round_predictions:\n",
    "        predictions['stores'] = torch.round(predictions['stores'])\n",
    "    \n",
    "    # print(f\"Predictions shape: {predictions['stores'].shape}\")\n",
    "    print(f\"Sample predictions (first 10): {predictions['stores'][:10]}\")\n",
    "    # print(f\"Mean of predictions: {predictions['stores'].mean()}\")\n",
    "    # print(f\"Time period used: {time_period_idx}\")\n",
    "    # print(f\"Predictions rounded: {round_predictions}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Function to save predictions in submission format\n",
    "def save_predictions_to_submission_format(predictions, output_filename=\"predictions_submission.csv\", \n",
    "                                        reference_data_path=\"vn2_data/Week 0 - 2024-04-08 - Initial State.csv\"):\n",
    "    \"\"\"\n",
    "    Save model predictions in the submission template format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : dict\n",
    "        Dictionary containing model predictions with 'stores' key\n",
    "    output_filename : str\n",
    "        Name of the output CSV file\n",
    "    reference_data_path : str\n",
    "        Path to reference data file to get Store and Product mapping\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load reference data to get Store and Product mapping\n",
    "    print(f\"Loading reference data from {reference_data_path}...\")\n",
    "    reference_data = pd.read_csv(reference_data_path)\n",
    "    \n",
    "    # Extract Store and Product columns\n",
    "    store_product_mapping = reference_data[['Store', 'Product']].copy()\n",
    "    \n",
    "    # Get predictions tensor and convert to numpy\n",
    "    predictions_tensor = predictions['stores'].cpu().numpy()  # Convert to CPU numpy array\n",
    "    \n",
    "    # Flatten predictions to match the number of store-product combinations\n",
    "    # predictions_tensor shape is [batch_size, n_stores, n_warehouses]\n",
    "    # We need to flatten it to match the number of rows in reference data\n",
    "    if predictions_tensor.ndim == 3:\n",
    "        # If 3D, flatten the last two dimensions\n",
    "        predictions_flat = predictions_tensor.reshape(-1)\n",
    "    else:\n",
    "        # If already 2D or 1D, use as is\n",
    "        predictions_flat = predictions_tensor.flatten()\n",
    "    \n",
    "    # Ensure we have the right number of predictions\n",
    "    if len(predictions_flat) != len(store_product_mapping):\n",
    "        print(f\"Warning: Number of predictions ({len(predictions_flat)}) doesn't match number of store-product combinations ({len(store_product_mapping)})\")\n",
    "        # Truncate or pad as needed\n",
    "        if len(predictions_flat) > len(store_product_mapping):\n",
    "            predictions_flat = predictions_flat[:len(store_product_mapping)]\n",
    "        else:\n",
    "            # Pad with zeros if we have fewer predictions\n",
    "            padding = np.zeros(len(store_product_mapping) - len(predictions_flat))\n",
    "            predictions_flat = np.concatenate([predictions_flat, padding])\n",
    "    \n",
    "    # Add predictions to the dataframe\n",
    "    store_product_mapping['Prediction'] = predictions_flat.astype(int)\n",
    "    \n",
    "    # Save to CSV\n",
    "    print(f\"Saving predictions to {output_filename}...\")\n",
    "    store_product_mapping.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(store_product_mapping)} predictions to {output_filename}\")\n",
    "    print(f\"Sample predictions:\")\n",
    "    print(store_product_mapping.head(10))\n",
    "    print(f\"Prediction statistics:\")\n",
    "    print(f\"  Mean: {store_product_mapping['Prediction'].mean():.2f}\")\n",
    "    print(f\"  Min: {store_product_mapping['Prediction'].min()}\")\n",
    "    print(f\"  Max: {store_product_mapping['Prediction'].max()}\")\n",
    "    print(f\"  Non-zero predictions: {(store_product_mapping['Prediction'] > 0).sum()}\")\n",
    "    \n",
    "    return store_product_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the config files\n",
    "In this example, we will apply a Vanilla Neural Network to a setting of one store under a lost demand assumption.\n",
    "Go to the respective config files to change the hyperparameters of the neural network or the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_setting_file = 'config_files/settings/vn2_round_1.yml'\n",
    "\n",
    "config_hyperparams_file = 'config_files/policies_and_hyperparams/data_driven_net.yml' # Multi-layer perceptron\n",
    "# config_hyperparams_file = 'config_files/policies_and_hyperparams/mean_last_x.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/ma4177/Neural_inventory_control/data_handling.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(demand)\n"
     ]
    }
   ],
   "source": [
    "with open(config_setting_file, 'r') as file:\n",
    "    config_setting = yaml.safe_load(file)\n",
    "\n",
    "with open(config_hyperparams_file, 'r') as file:\n",
    "    config_hyperparams = yaml.safe_load(file)\n",
    "\n",
    "setting_keys = 'seeds', 'test_seeds', 'problem_params', 'params_by_dataset', 'observation_params', 'store_params', 'warehouse_params', 'echelon_params', 'sample_data_params'\n",
    "hyperparams_keys = 'trainer_params', 'optimizer_params', 'nn_params'\n",
    "seeds, test_seeds, problem_params, params_by_dataset, observation_params, store_params, warehouse_params, echelon_params, sample_data_params = [\n",
    "    config_setting[key] for key in setting_keys\n",
    "    ]\n",
    "\n",
    "trainer_params, optimizer_params, nn_params = [config_hyperparams[key] for key in hyperparams_keys]\n",
    "observation_params = DefaultDict(lambda: None, observation_params)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_creator = DatasetCreator()\n",
    "\n",
    "# For realistic data, train, dev and test sets correspond to the same products, but over disjoint periods.\n",
    "# We will therefore create one scenario, and then split the data into train, dev and test sets by \n",
    "# \"copying\" all non-period related information, and then splitting the period related information\n",
    "if sample_data_params['split_by_period']:\n",
    "    \n",
    "    scenario = Scenario(\n",
    "        periods=None,  # period info for each dataset is given in sample_data_params\n",
    "        problem_params=problem_params, \n",
    "        store_params=store_params, \n",
    "        warehouse_params=warehouse_params, \n",
    "        echelon_params=echelon_params, \n",
    "        num_samples=params_by_dataset['train']['n_samples'],  # in this case, num_samples=number of products, which has to be the same across all datasets\n",
    "        observation_params=observation_params, \n",
    "        seeds=seeds\n",
    "        )\n",
    "    \n",
    "    train_dataset, dev_dataset, test_dataset = dataset_creator.create_datasets(\n",
    "        scenario, \n",
    "        split=True, \n",
    "        by_period=True, \n",
    "        periods_for_split=[sample_data_params[k] for  k in ['train_periods', 'dev_periods', 'test_periods']],)\n",
    "\n",
    "# For synthetic data, we will first create a scenario that we will divide into train and dev sets by sample index.\n",
    "# Then, we will create a separate scenario for the test set, which will be exaclty the same as the previous scenario, \n",
    "# but with different seeds to generate demand traces, and with a longer time horizon.\n",
    "# One can use this method of generating scenarios to train a model using some specific problem primitives, \n",
    "# and then test it on a different set of problem primitives, by simply creating a new scenario with the desired primitives.\n",
    "else:\n",
    "    max_periods = max(params_by_dataset['train']['periods'], params_by_dataset['dev']['periods'])\n",
    "    scenario = Scenario(\n",
    "        periods=max_periods, \n",
    "        # periods=params_by_dataset['train']['periods'], \n",
    "        problem_params=problem_params, \n",
    "        store_params=store_params, \n",
    "        warehouse_params=warehouse_params, \n",
    "        echelon_params=echelon_params, \n",
    "        num_samples=params_by_dataset['train']['n_samples'] + params_by_dataset['dev']['n_samples'], \n",
    "        observation_params=observation_params, \n",
    "        seeds=seeds\n",
    "        )\n",
    "\n",
    "    train_dataset, dev_dataset = dataset_creator.create_datasets(scenario, split=True, by_sample_indexes=True, sample_index_for_split=params_by_dataset['dev']['n_samples'])\n",
    "\n",
    "    scenario = Scenario(\n",
    "        params_by_dataset['test']['periods'], \n",
    "        problem_params, \n",
    "        store_params, \n",
    "        warehouse_params, \n",
    "        echelon_params, \n",
    "        params_by_dataset['test']['n_samples'], \n",
    "        observation_params, \n",
    "        test_seeds\n",
    "        )\n",
    "\n",
    "    test_dataset = dataset_creator.create_datasets(scenario, split=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=params_by_dataset['train']['batch_size'], shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=params_by_dataset['dev']['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params_by_dataset['test']['batch_size'], shuffle=False)\n",
    "data_loaders = {'train': train_loader, 'dev': dev_loader, 'test': test_loader}\n",
    "\n",
    "neural_net_creator = NeuralNetworkCreator\n",
    "model = neural_net_creator().create_neural_network(scenario, nn_params, device=device)\n",
    "\n",
    "loss_function = PolicyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=optimizer_params['learning_rate'])\n",
    "\n",
    "simulator = Simulator(device=device)\n",
    "trainer = Trainer(device=device)\n",
    "\n",
    "# We will create a folder for each day of the year, and a subfolder for each model\n",
    "# When executing with different problem primitives (i.e. instance), it might be useful to create an additional subfolder for each instance\n",
    "trainer_params['base_dir'] = 'saved_models'\n",
    "trainer_params['save_model_folders'] = [trainer.get_year_month_day(), nn_params['name']]\n",
    "\n",
    "# We will simply name the model with the current time stamp\n",
    "trainer_params['save_model_filename'] = trainer.get_time_stamp()\n",
    "\n",
    "# Load previous model if load_model is set to True in the config file\n",
    "if trainer_params['load_previous_model']:\n",
    "    print(f'Loading model from {trainer_params[\"load_model_path\"]}')\n",
    "    model, optimizer = trainer.load_model(model, optimizer, trainer_params['load_model_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: load a model to continue training\n",
    "load_model = False\n",
    "if load_model:\n",
    "    model_filename = \"saved_models/2025_10_04/model_1.pt\"\n",
    "    model, optimizer = trainer.load_model(model, optimizer, model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training. You can stop training whenever you want. This will keep the model (ie the neural network) with the weights of the last iteration. If you want to use the model that achieved the smallest dev loss, just run one of the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Average per-period train loss: 0.22162883798089142\n",
      "Average per-period dev loss: -0.04996660705271737\n",
      "Best per-period dev loss: -0.04996660705271737\n",
      "epoch: 2\n",
      "Average per-period train loss: -0.09376799003457703\n",
      "Average per-period dev loss: -0.36829878432663676\n",
      "Best per-period dev loss: -0.36829878432663676\n",
      "epoch: 3\n",
      "Average per-period train loss: -0.4926386252505957\n",
      "Average per-period dev loss: -0.6796012251556649\n",
      "Best per-period dev loss: -0.6796012251556649\n",
      "epoch: 4\n",
      "Average per-period train loss: -0.6018010006884694\n",
      "Average per-period dev loss: -0.8550520927333845\n",
      "Best per-period dev loss: -0.8550520927333845\n",
      "epoch: 5\n",
      "Average per-period train loss: -0.8672846364979738\n",
      "Average per-period dev loss: -1.090017974072779\n",
      "Best per-period dev loss: -1.090017974072779\n",
      "epoch: 6\n",
      "Average per-period train loss: -1.0211038830743546\n",
      "Average per-period dev loss: -1.1815505607600505\n",
      "Best per-period dev loss: -1.1815505607600505\n",
      "epoch: 7\n",
      "Average per-period train loss: -1.1355938700585377\n",
      "Average per-period dev loss: -1.2109954865654469\n",
      "Best per-period dev loss: -1.2109954865654469\n",
      "epoch: 8\n",
      "Average per-period train loss: -1.2082841032017393\n",
      "Average per-period dev loss: -1.3651116162071921\n",
      "Best per-period dev loss: -1.3651116162071921\n",
      "epoch: 9\n",
      "Average per-period train loss: -1.3314137483635475\n",
      "Average per-period dev loss: -1.5643842990005865\n",
      "Best per-period dev loss: -1.5643842990005865\n",
      "epoch: 10\n",
      "Average per-period train loss: -1.447193389222422\n",
      "Average per-period dev loss: -1.6227526240242747\n",
      "Best per-period dev loss: -1.6227526240242747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams_by_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Neural_inventory_control/trainer.py:66\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs, loss_function, simulator, model, data_loaders, optimizer, problem_params, observation_params, params_by_dataset, trainer_params)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mTrain a parameterized policy\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    and the metric to use for choosing the best model\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs): \u001b[38;5;66;03m# Make multiple passes through the dataset\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Do one epoch of training, including updating the model parameters\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     average_train_loss, average_train_loss_to_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_by_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mperiods\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_by_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore_periods\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_train_losses\u001b[38;5;241m.\u001b[39mappend(average_train_loss_to_report)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m trainer_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_dev_every_n_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Neural_inventory_control/trainer.py:163\u001b[0m, in \u001b[0;36mTrainer.do_one_epoch\u001b[0;34m(self, optimizer, data_loader, loss_function, simulator, model, periods, problem_params, observation_params, train, ignore_periods, discrete_allocation)\u001b[0m\n\u001b[1;32m    160\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m total_reward, reward_to_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_allocation\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_reward\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Rewards from period 0\u001b[39;00m\n\u001b[1;32m    167\u001b[0m epoch_loss_to_report \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward_to_report\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Rewards from period ignore_periods onwards\u001b[39;00m\n",
      "File \u001b[0;32m~/Neural_inventory_control/trainer.py:204\u001b[0m, in \u001b[0;36mTrainer.simulate_batch\u001b[0;34m(self, loss_function, simulator, model, periods, problem_params, data_batch, observation_params, ignore_periods, discrete_allocation)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discrete_allocation:  \u001b[38;5;66;03m# Round actions to the nearest integer if specified\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     action \u001b[38;5;241m=\u001b[39m {key: val\u001b[38;5;241m.\u001b[39mround() \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 204\u001b[0m observation, reward, terminated, _, _  \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m loss_function(\u001b[38;5;28;01mNone\u001b[39;00m, action, reward)\n\u001b[1;32m    208\u001b[0m batch_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_reward\n",
      "File \u001b[0;32m~/Neural_inventory_control/environment.py:152\u001b[0m, in \u001b[0;36mSimulator.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_time_features(\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_data, \n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation, \n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_params, \n\u001b[1;32m    148\u001b[0m     current_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_period\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Calculate reward and update store inventories\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_store_reward_and_update_store_inventories\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_demands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize_profit\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Calculate reward and update warehouse inventories\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_warehouses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Neural_inventory_control/environment.py:245\u001b[0m, in \u001b[0;36mSimulator.calculate_store_reward_and_update_store_inventories\u001b[0;34m(self, current_demands, action, observation, maximize_profit)\u001b[0m\n\u001b[1;32m    227\u001b[0m store_lead_times \u001b[38;5;241m=\u001b[39m observation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlead_times\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# observation['store_inventories'] = self.update_inventory_for_heterogeneous_lead_times(\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m#     store_inventory, \u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m#     post_inventory_on_hand, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# print(f'lead time: {int(observation[\"lead_times\"][0, 0])}')\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# print(f'action: {action[\"stores\"][0]}')\u001b[39;00m\n\u001b[1;32m    242\u001b[0m observation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_inventories\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmove_left_add_first_col_and_append(\n\u001b[1;32m    243\u001b[0m     post_inventory_on_hand, \n\u001b[1;32m    244\u001b[0m     observation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_inventories\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlead_times\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m    246\u001b[0m     action[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reward\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(\n",
    "    trainer_params['epochs'], \n",
    "    loss_function, simulator, \n",
    "    model, \n",
    "    data_loaders, \n",
    "    optimizer, \n",
    "    problem_params, \n",
    "    observation_params, \n",
    "    params_by_dataset, \n",
    "    trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set weights to the version that achieved the smallest dev loss (ie we are using early stopping)\n",
    "best_model_state = get_best_model_state(model, trainer, optimizer, config_setting, config_hyperparams)\n",
    "model.load_state_dict(best_model_state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Path: saved_models/2025_10_06/model_32_demands.pt\n",
      "Best dev loss: -1.622753\n",
      "Best epoch: 10\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save the trained model.\n",
    "# This will save the model that achieved the smallest dev_loss during training\n",
    "save_model = True\n",
    "if save_model:\n",
    "    # The function will save the model that achieved the smallest dev_loss during training\n",
    "    model_filename = \"model_32_demands\"\n",
    "    saved_model_path = save_trained_model(model_filename, model, trainer, optimizer, config_setting, config_hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from saved_models/2025_10_06/model_32_demands.pt\n"
     ]
    }
   ],
   "source": [
    "# optional: load a model to evaluate. Otherwise, will use the model from training.\n",
    "load_model_for_test = True\n",
    "if load_model_for_test:\n",
    "    model_filename = \"saved_models/2025_10_06/model_32_demands.pt\"\n",
    "    model, optimizer = trainer.load_model(model, optimizer, model_filename)\n",
    "    print(f\"Loaded model from {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average per-period per-product test loss: -1.6227526240242747\n"
     ]
    }
   ],
   "source": [
    "average_test_loss, average_test_loss_to_report = trainer.test(\n",
    "    loss_function, \n",
    "    simulator, \n",
    "    model, \n",
    "    data_loaders, \n",
    "    optimizer, \n",
    "    problem_params, \n",
    "    observation_params, \n",
    "    params_by_dataset, \n",
    "    discrete_allocation=False\n",
    "    )\n",
    "\n",
    "print(f'Average per-period per-product test loss: {average_test_loss_to_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration files...\n",
      "Loading data files...\n",
      "Making prediction...\n",
      "Sample predictions (first 10): tensor([[[1.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[7.]],\n",
      "\n",
      "        [[7.]],\n",
      "\n",
      "        [[3.]],\n",
      "\n",
      "        [[2.]],\n",
      "\n",
      "        [[8.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[4.]],\n",
      "\n",
      "        [[6.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Use with different config files\n",
    "predictions = make_predictions_from_config(\n",
    "    model, device,\n",
    "    config_setting_file=config_setting_file,\n",
    "    config_hyperparams_file=config_hyperparams_file,\n",
    "    inventory_state_path='vn2_processed_data/all_data/inventory_state.pt',\n",
    "    data_dir='vn2_processed_data/all_data/',\n",
    "    round_predictions=True\n",
    ")\n",
    "\n",
    "# optional: save predictions in submission format\n",
    "save_the_predictions = False\n",
    "if save_the_predictions:\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"predictions/submission_{timestamp}.csv\"\n",
    "    save_predictions_to_submission_format(\n",
    "        predictions,\n",
    "        output_filename=output_filename,\n",
    "        reference_data_path=\"vn2_data/Week 0 - 2024-04-08 - Initial State.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
